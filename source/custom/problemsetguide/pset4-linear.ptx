<section xml:id="sec-pset4-linear">
    <title>Problem Set 4</title>
    <paragraphs>
        <title>Instructions</title>
        <p>
            Prior to beginning this problem set, consider reading the Problem Set Success Guide <xref ref="pset-intro"/> for advice and clarity around expectations for Problem Sets in this course. 
            Upload your solutions to all problems on this page to gradescope as a single .pdf file, remembering to assign pages appropriately for each question. 
            Complete instructions for Problem Sets are available on Canvas.
        </p>
    </paragraphs>

    <problem>
        <title>(Problem 1)</title>
        <introduction>
            <p>
                In this problem, <m>T\colon V\to W</m> denotes a linear transformation. 
            </p>
            <task>
                <statement>
                    <p>
                        Show that if <m>\ker(T)=\{\vec{0}\}</m>, then <m>T</m> must be injective. 
                        <em>Note:</em> we saw and used this fact in class, but we did not prove it; the point of this exercise is for you to prove it here.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Suppose that <m>\setList{\vec{v}_1,\vec{v}_2,\vec{v}_3}</m> are vectors in <m>V</m> and that the set <m>\setList{T(\vec{v}_1),T(\vec{v}_2),T(\vec{v}_3)}</m> is a linearly independent set. 
                        Does it follows that <m>\setList{\vec{v}_1,\vec{v}_2,\vec{v}_3}</m> is also linearly independent? 
                        If <q>yes</q>, explain why; if <q>no</q>, provide a counterexample to the claim. 
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Suppose that <m>\setList{\vec{u}_1,\vec{u}_2,\vec{u}_3}</m> are vectors in <m>V</m>. 
                        If the set <m>\setList{T(\vec{u}_1),T(\vec{u}_2),T(\vec{u}_3)}</m> spans <m>W</m>, does it necessarily follows that <m>\setList{\vec{u}_1,\vec{u}_2,\vec{u}_3}</m> spans <m>V</m>?
                        If <q>yes</q>, explain why; if <q>no</q>, provide a counterexample to the claim. 
                    </p>
                </statement>
            </task>
        </introduction>
        <solution>
            <task>
                <statement>
                    <p>
                        Suppose that <m>T\colon V\to W</m> is some linear transformation. 
                        To show that <m>T</m> is injective, we need to prove that if <m>\vec{u},\vec{v}\in V</m> are vectors for which <m>T(\vec{u})=T(\vec{v})</m> then, in fact, we have <m>\vec{u}=\vec{v}</m>. 
                    </p>
                    <p>
                        To that end, suppose that <m>T(\vec{u})=T(\vec{u})</m>. 
                        It follows, then,  that <m>T(\vec{u}-\vec{v})=T(\vec{u})-T(\vec{v})=\vec{0}</m>. 
                        In other words, <m>\vec{u}-\vec{v}\in\ker(T)</m>. 
                        But since our assumption is that <m>\ker(T)=\{\vec{0}\}</m>, it follows that <m>\vec{u}-\vec{v}=\vec{0}</m> or <m>\vec{u}=\vec{v}</m>, from which it follows that <m>T</m> is injective.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Yes, it does follow.
                        Suppose otherwise that the set <m>\setList{\vec{v}_1,\vec{v}_2,\vec{v}_3}</m> were linearly dependent. 
                        It would then follow that one of the vectors, say <m>\vec{v}_1</m>, is a linear combination of the others:
                        <me>
                            \vec{v}_1=a\vec{v}_2+b\vec{v}_3.
                        </me>
                        But then, by applying the transformation <m>T</m>, we would have
                        <me>
                            T(\vec{v}_1)=aT(\vec{v}_2)+bT(\vec{v}_3).
                        </me>
                        But this would imply that the set <m>\setList{T(\vec{v}_1),T(\vec{v}_2),T(\vec{v}_3)}</m>, which is contrary to our assumptions. 
                        We conclude that the set <m>\setList{\vec{v}_1,\vec{v}_2,\vec{v}_3}</m> is therefore linearly independent.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        No, not necessarily. 
                        For instance, if <m>\vec{u}_1=\vec{e}_1, \vec{u}_2=\vec{e}_2,\vec{u}_3=\vec{e}_3</m> denote the first three standard basis vectors in <m>\IR^4</m> and <m>T\colon\IR^4\to\IR^3</m> is the linear transformation given by
                        <me>
                            \left[\begin{array}{cccc}1&amp; 0&amp;0&amp;0\\ 0&amp; 1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\end{array}\right],
                        </me>
                        then since the columns of this matrix span <m>\IR^3</m> but the vectors <m>\vec{u}_1,\vec{u}_2,\vec{u}_3</m> do not span the domain <m>(\IR^4)</m>, we have a counter-example. 
                    </p>
                </statement>
            </task>
        </solution>
    </problem>

    <problem>
        <title>(Problem 2)</title>
       <introduction>
        <p>
            Let <m>T\colon M_{2,2}\to\IR</m> denote the transformation given by the rule:
            <me>T\left(\left[\begin{array}{cc}a&amp; b\\ c&amp; d\end{array}\right]\right)=a+d.</me>
        </p>
        <task>
            <statement>
                <p>
                    Show that <m>T</m> is a linear map. 
                </p>
            </statement>
            </task>
            <task>
            <statement>
                <p>
                    Explain and demonstrate how to calculate a basis for the kernel of <m>T</m> and a basis for the image of <m>T</m>.
                    Is <m>T</m> injective? Is <m>T</m> surjective?
                </p>
            </statement>
           </task>
           <task>
            <statement>
                <p>
                    Verify the rank-nullity theorem for this linear transformation. 
                </p>
            </statement>
           </task>
       </introduction>
       <solution>
        <task>
            <statement>
                <p>
                    Let <m>A=\left[\begin{array}{cc}a&amp; b\\ c&amp; d\end{array}\right]</m> and <m>B=\left[\begin{array}{cc}x&amp; y\\ z&amp; w\end{array}\right]</m>.
                    Then, we have:
                    <md>
                        <mrow>T(A+B) \amp =T\left(\left[\begin{array}{cc}a+x&amp; b+y\\ c+z&amp; d+w\end{array}\right]\right)</mrow>
                        <mrow> \amp =(a+x)+(d+w).</mrow>
                    </md>
                    On the other hand, 
                    <md>
                        <mrow>T(A)+T(B) \amp =(a+d)+(x+w).</mrow>
                    </md>
                    These expressions agree, so we conclude that <m>T(A)+T(B)=T(A+B)</m> for all elements of <m>M_{2,2}</m>. 
                </p>
                <p>
                    Similarly, if <m>k</m> is a scalar, then <m>T(kA)=T(\left[\begin{array}{cc}ka&amp; kb\\ kc&amp; kd\end{array}\right])=ka+kd</m>.
                    On the other hand, <m>kT(A)=k(a+d)=ka+kd</m>. So, <m>T</m> respects scalar multiplication as well and <m>T</m> is linear.  
                </p>
            </statement>
        </task>
        <task>
            <p>
                By definition, the kernel of <m>T</m> is the set of all matrices for which <m>T(A)=0</m>. 
                This can described as:
                <me>
                    \ker(T)=\left\{\left[\begin{array}{cc}a&amp; b\\ c&amp; -a\end{array}\right]\colon a,b,c\in\IR\right\}.
                </me>
                Using this description, an arbitrary element of the kernel can be written as:
                <me>
                    a\left[\begin{array}{cc}1&amp; 0\\ 0&amp; -1\end{array}\right]+b\left[\begin{array}{cc}0&amp; 1\\ 0&amp; 0\end{array}\right]+c\left[\begin{array}{cc}0&amp; 0\\ 1&amp; 0\end{array}\right],
                </me>
                which tells us that the set <m>S=\setList{\left[\begin{array}{cc}1&amp; 0\\ 0&amp; -1\end{array}\right],\left[\begin{array}{cc}0&amp; 1\\ 0&amp; 0\end{array}\right],\left[\begin{array}{cc}0&amp; 0\\ 1&amp; 0\end{array}\right]}</m> spans the kernel (since any element is a linear combination of the matrices in <m>S</m>).
            </p>
            <p>
                The only way that the above linear combination of matrices is equal to the zero matrix is when <m>a,b,c</m> are all themselves equal to <m>0</m>. 
                It follows that the set <m>S</m> is linear independent and that <m>S</m> is therefore a basis for the kernel. 
            </p>
            <p>
                Considering a matrix of the form <m>\left[\begin{array}{cc}a&amp; 0\\ 0&amp; 0\end{array}\right]</m>. Applying <m>T</m>, we get <m>a\in\IR</m>, so the image of <m>T</m> is all of <m>\IR</m>. 
                It follows that <m>\{1\}</m> is a basis. 
            </p>
            <p>
                Since the kernel is non-trivial, the map is not injective. 
                Since the image is all of <m>\IR</m>, the map is surjective.
            </p>
        </task>
        <task>
            <p>
                By our calculations above, the rank of <m>T</m> is equal to <m>1</m> and the nullity is equal to <m>3</m>. 
                Adding these together gives <m>4</m>, the dimension of <m>M_{2,2}</m>
            </p>
        </task>
       </solution>
    </problem>

    <!--<problem>
        <title>(Problem 3)</title>
        <introduction>
            <p>
                Let <m>\IR^+=\{x\in\IR|\ x&gt;0\}</m> denote the set of positive real numbers. 
                Define a new addition on <m>\mathbb{R}^+</m> by the rule <m>x\oplus y=xy</m> (so, in particular, <m>2\oplus 3=6</m>) and define scalar multiplication by <m>\alpha\odot x=x^\alpha</m>. 
                The set <m>\mathbb{R}^+</m> with these operations is a vector space and you can verify this by checking that all 8 of our Vector Space properties are true for <m>\mathbb{R}^+</m>.
                We won't ask you to do all of them here, but we will ask a few:
            </p>
        </introduction>
        <task>
            <statement>
                <p>
                    Explain why scalar multiplication distributes over scalar addition; that is, explain why <m>(a+b)\odot x=(a\odot x)\oplus (b\odot x)</m> for every <m>x\in\mathbb{R}^+</m> and <m>a,b\in\mathbb{R}</m>.
                </p>
            </statement>
        </task>
        <task>
            <statement>
                <p>
                    Explain why an additive identity exists: that is, explain why there is some <m>z\in\mathbb{R}^+</m> for which <m>x\oplus z=x</m> for every <m>x\in\mathbb{R}^+</m>.
                </p>
            </statement>
        </task>
        <task>
            <statement>
                <p>
                    Explain why additive inverses exist; that is, explain why, for each <m>y\in\mathbb{R}^+</m>, there exists an element <m>b</m> for which <m>y\oplus b=z</m>, where <m>z</m> is the additive identity you identified above.
                </p>
            </statement>
        </task>
    </problem>-->

    <problem>
        <title>(Problem 3)</title>
        <introduction>
            <p>
                Let <m>W</m> denote the plane living in <m>\IR^4</m> that is given by the following set of equations:
                <md>
                    <mrow>x+y+z+w&amp;=0</mrow>
                    <mrow>x-y+z-w&amp;=0</mrow>
                </md>
            </p>
            <task>
                <statement>
                    <p>
                        Explain and demonstrate how to find two vectors <m>\vec{u},\vec{v}</m> for which <m>W=\vspan\{\vec{u},\vec{v}\}</m> is a basis for <m>W</m>, confirming that <m>W</m> is indeed a plane in 4-space.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Explain and demonstrate how to find an example of a linear transformation <m>T\colon\IR^3\to\IR^4</m> for which the image of <m>T</m> is equal to <m>W</m>. 
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Explain and demonstrate how to find one example of a linear transformation <m>S\colon\IR^2\to\IR^4</m> for which the image of <m>S</m> is equal to some <m>1</m>-dimensional subspace of <m>W</m>.
                    </p>
                </statement>
            </task>
            <sage language="octave">
                <input>
                    
                </input>
                <output>
                    
                </output>
            </sage>
        </introduction>
        
        <solution>
            <task>
                <p>
                    By definition, <m>W</m> is the solution space of the given homogeneous linear system. 
                    Using methods we are by now familiar with, a basis for this solution space is given by:
                    <me>\left\{\left[\begin{array}{c}-1\\0\\1\\0\end{array}\right],\left[\begin{array}{c}0\\-1\\0\\1\end{array}\right]\right\}.</me>
                </p>
            </task>
            <task>
                <p>
                    Methods and solutions will vary.
                    Since the image of a linear transformation is equal to the span of the columns of the corresponding standard matrix, one approach is find a <m>4\times 3</m> standard matrix for which its columns span exactly <m>W</m>. 
                    One such example is:
                    <me>
                        A=\left[\begin{array}{ccc}-1&amp;0&amp;0\\0&amp;-1&amp;0\\1&amp;0&amp;0\\0&amp;1&amp;0\end{array}\right].
                    </me>
                    
                </p>
            </task>
            <task>
                <p>
                    Similar to above, we can search for an appropriate <m>4\times 2</m> standard matrix. 
                    Here, we want the columns to span a line that is contained in <m>W</m>.
                    One way to do this is to let both columns be equal to one of the two spanning vectors. 
                </p>
            </task>
        </solution>
    </problem>

    <problem>
        <title>(Problem 4)</title>
        <introduction>
            <p>
                Let <m>A</m> be an <m>m\times n</m> matrix.
                The <term>transpose</term> of <m>A</m> is the <m>n\times m</m> matrix that is obtained by reflecting the matrix <m>A</m> about the main top-left to bottom-right diagonal and is denoted by <m>A^T</m>.
                For instance, the following is an example of a matrix <m>B</m> and its transpose <m>B^T</m>:
                <me>B=\left[\begin{array}{ccc}1&amp; 2&amp;3\\ 1&amp; 2&amp; 4\end{array}\right],\ \ B^T=\left[\begin{array}{cc}1&amp; 1\\ 2&amp; 2\\3&amp; 4\end{array}\right].</me>
                Now suppose <m>f\colon\mathbb{R}^n\to\mathbb{R}^m</m> is a linear transformation with standard matrix <m>A</m> and let <m>g\colon\mathbb{R}^m\to\mathbb{R}^n</m> denote the linear transformation with standard matrix <m>A^T</m>.
            </p>
            <task>
                <statement>
                    <p>
                        With <m>A=\left[\begin{array}{cccc}1&amp; 0&amp;2&amp;-3\\3&amp; 2&amp;-1&amp;-1\\4&amp; 2&amp;1&amp;-4\end{array}\right]</m> and notation as defined above, calculate the rank and nullity of the transformations <m>f</m> and <m>g</m>.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Now suppose that <m>f\colon\mathbb{R}^n\to\mathbb{R}^m</m> is an arbitrary linear transformation, let <m>A</m> denote its standard matrix, and let <m>g</m> be the transformation corresponding to the transpose <m>B=A^T</m>.
                        Explain why the rank of <m>f</m> will always be equal to the rank of <m>g</m>.
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                        Notation as in (b), explain why <m>\textrm{null(g)}-\textrm{null(f)}=m-n</m> and conclude that <m>\textrm{null}(f)=\textrm{null}(g)</m> if and only if <m>m=n</m>.
                    </p>
                </statement>
            </task>
            <sage language="octave">
                <input>
                    
                </input>
                <output>
                    
                </output>
            </sage>
        </introduction>
        <solution>
            <task>
            <p>
                We start by calculating the RREF of <m>A</m>:
                <me>\RREF(A)=\left[\begin{array}{cccc}1&amp; 0 &amp;2 &amp;-3\\ 0&amp; 1&amp; 3.5 &amp;0\\0 &amp;0 &amp;0 &amp;0\end{array}\right]</me>
                Since there are two pivot columns, the rank of <m>A</m> is equal to <m>2</m>. 
                Since there are two non-pivot columns, the nullity of <m>A</m> is equal to <m>2</m>. 
            </p>
            <p>
                One way to calculate the rank and nullity of <m>A^T</m> is to calculuate the matrix <m>A^T</m> and then calculate its RREF. 
                Another approach to solving the problem is: since the rows of <m>A</m> are the columns of <m>A^T</m> and vice-versa and, since we know that dimension of the row-space of a matrix is equal to the dimension of the column space, it follows that the rank of <m>g</m> must be the same as the rank of <m>f</m>. 
                Since the dimension of the domain is different (it's <m>3</m> in this case), the nullity of <m>g</m> is just <m>1</m>.
            </p>
            </task>
            <task>
                <p>
                    In general, if <m>A </m> is the standard matrix of a linear transformation <m>f</m>, then its rank is the dimension of the column space of the corresponding standard matrix. 
                    Since this is always equal to the dimension of its row-space and the row-space is the same as the column space of the <em>transpose</em>, it follows that <m>f</m> and <m>g</m> have the same rank. 
                </p>
            </task>
            <task>
                <p>
                    Applying the rank-nullity theorem to <m>f</m> and <m>g</m> yield the following equalities:
                    <md>
                        <mrow>\textrm{rank}(f)+\textrm{null(f)} \amp =n</mrow>
                        <mrow>\textrm{rank}(g)+\textrm{null(g)} \amp =m.</mrow>
                    </md>
                    Subtracting and using the fact that the ranks are equal gives:
                    <me>
                        \textrm{null}(g)-\textrm{null}(f)=m-n.
                    </me>
                    In particulary, the difference is zero only when <m>m=n</m>. 
                </p>
            </task>
        </solution>
       
    </problem>
</section>